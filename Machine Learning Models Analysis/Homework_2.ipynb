{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "characteristic-crash",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Homework 2 </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disclaimer\n",
    "* This notebook has been written by Benjamin Amar in 2023 DSAIS class at Em-Lyon.\n",
    "* Generative AI (ChatGPT 4) has been used for debugging, inspiration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e0e53d",
   "metadata": {},
   "source": [
    "**I- Reading Assignment**\n",
    "\n",
    "[James, G., Witten, D., Hastie, T., Tibshirani, R., & Taylor, J. (2023). An Introduction to Statistical Learning‚ÄØ: With Applications in Python (1st ed. 2023 edition). Springer.](https://www.statlearning.com/)\n",
    "\n",
    "- Read Chapter 8, Section 1 (8.1: pages 331-342)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math as m\n",
    "import seaborn as sns\n",
    "import import_ipynb\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from itertools import combinations\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-ending",
   "metadata": {},
   "source": [
    "**II- Binary Classification**\n",
    "\n",
    "1- Select your binary outcome\n",
    "\n",
    "Amongst your categorical variables, select a binary variable to be used as an outcome.\n",
    "It you have no binary variable, then create a binary variable from one of your categorical variables.\n",
    "\n",
    "2- Divide your dataset into a test sample and a training sample with a ratio of 20% vs 80% respectively. <br>\n",
    "Be careful to do so that your outcomes remain representative of the initial data set and well shuffled.\n",
    "\n",
    "3- Select one classifier and fit it on the training set then estimate its score both on the training set and the test set. <br>Use the accuracy, the ROC AUC, the F1 score and the Kappa to estimate the performance of your classifier.\n",
    "\n",
    "4- Repeat the same code on two other different classifiers: \n",
    "\n",
    "- Recommendation: create a function that does all the job and run it using three different classifiers\n",
    ". \n",
    "- Which is the best classifier ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Toydataset.csv loaded successfully! üëç\n"
     ]
    }
   ],
   "source": [
    "path = \"Toydataset.csv\"\n",
    "data = pd.DataFrame()\n",
    "\n",
    "if path.endswith('.csv'):\n",
    "    data = pd.read_csv(path, index_col=0)\n",
    "\n",
    "elif path.endswith('.xlsx') or path.endswith('.xls'):\n",
    "    data = pd.read_excel(path)\n",
    "\n",
    "elif path.endswith('.txt'):\n",
    "    data = pd.read_csv(path, sep='*', encoding='latin')\n",
    "\n",
    "else:\n",
    "    print(f\"Unsupported file format. Please provide a .csv or .xlsx file\")\n",
    "    \n",
    "if data is not None:\n",
    "    print(f\"Dataframe {path} loaded successfully! üëç\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datac = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 18600 entries, 1.0 to 200.0\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Game              16537 non-null  object \n",
      " 1   Month_str         16549 non-null  object \n",
      " 2   Month             16538 non-null  float64\n",
      " 3   Year              16510 non-null  float64\n",
      " 4   YearTop1          18600 non-null  bool   \n",
      " 5   Hours_watched     16468 non-null  float64\n",
      " 6   Hours_streamed    16451 non-null  float64\n",
      " 7   Peak_viewers      16425 non-null  float64\n",
      " 8   Peak_channels     16494 non-null  float64\n",
      " 9   Streamers         16453 non-null  float64\n",
      " 10  Avg_viewers       16453 non-null  float64\n",
      " 11  Avg_channels      16552 non-null  float64\n",
      " 12  Avg_viewer_ratio  16515 non-null  float64\n",
      "dtypes: bool(1), float64(10), object(2)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "datac.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game</th>\n",
       "      <th>Month_str</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>YearTop1</th>\n",
       "      <th>Hours_watched</th>\n",
       "      <th>Hours_streamed</th>\n",
       "      <th>Peak_viewers</th>\n",
       "      <th>Peak_channels</th>\n",
       "      <th>Streamers</th>\n",
       "      <th>Avg_viewers</th>\n",
       "      <th>Avg_channels</th>\n",
       "      <th>Avg_viewer_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>League of Legends</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>False</td>\n",
       "      <td>94377226.0</td>\n",
       "      <td>1362044.0</td>\n",
       "      <td>530270.0</td>\n",
       "      <td>2903.0</td>\n",
       "      <td>129172.0</td>\n",
       "      <td>127021.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>True</td>\n",
       "      <td>47832863.0</td>\n",
       "      <td>830105.0</td>\n",
       "      <td>372654.0</td>\n",
       "      <td>2197.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64378.0</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>57.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>Dota 2</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>False</td>\n",
       "      <td>45185893.0</td>\n",
       "      <td>433397.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>44074.0</td>\n",
       "      <td>60815.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>104.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>Hearthstone</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>False</td>\n",
       "      <td>39936159.0</td>\n",
       "      <td>235903.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36170.0</td>\n",
       "      <td>53749.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>169.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>Call of Duty: Black Ops III</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>False</td>\n",
       "      <td>16153057.0</td>\n",
       "      <td>1151578.0</td>\n",
       "      <td>71639.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>214054.0</td>\n",
       "      <td>21740.0</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>14.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196.0</th>\n",
       "      <td>PlateUp!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>False</td>\n",
       "      <td>560064.0</td>\n",
       "      <td>18617.0</td>\n",
       "      <td>16476.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>4034.0</td>\n",
       "      <td>778.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>30.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197.0</th>\n",
       "      <td>Pok√É¬©mon GO</td>\n",
       "      <td>September</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>False</td>\n",
       "      <td>551596.0</td>\n",
       "      <td>16578.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>767.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>33.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>Bloons TD 6</td>\n",
       "      <td>September</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20142.0</td>\n",
       "      <td>10320.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>5673.0</td>\n",
       "      <td>752.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>September</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>False</td>\n",
       "      <td>533644.0</td>\n",
       "      <td>27014.0</td>\n",
       "      <td>11508.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>19.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200.0</th>\n",
       "      <td>Bloodborne</td>\n",
       "      <td>September</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36741.0</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>737.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18600 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Game  Month_str  Month    Year  YearTop1  \\\n",
       "Rank                                                                          \n",
       "1.0                   League of Legends        NaN    1.0  2016.0     False   \n",
       "2.0    Counter-Strike: Global Offensive    January    1.0  2016.0      True   \n",
       "3.0                              Dota 2    January    1.0  2016.0     False   \n",
       "4.0                         Hearthstone    January    1.0  2016.0     False   \n",
       "5.0         Call of Duty: Black Ops III    January    1.0  2016.0     False   \n",
       "...                                 ...        ...    ...     ...       ...   \n",
       "196.0                          PlateUp!        NaN    9.0  2023.0     False   \n",
       "197.0                       Pok√É¬©mon GO  September    9.0  2023.0     False   \n",
       "NaN                         Bloons TD 6  September    9.0  2023.0     False   \n",
       "199.0                               NaN  September    9.0  2023.0     False   \n",
       "200.0                        Bloodborne  September    9.0  2023.0     False   \n",
       "\n",
       "       Hours_watched  Hours_streamed  Peak_viewers  Peak_channels  Streamers  \\\n",
       "Rank                                                                           \n",
       "1.0       94377226.0       1362044.0      530270.0         2903.0   129172.0   \n",
       "2.0       47832863.0        830105.0      372654.0         2197.0        NaN   \n",
       "3.0       45185893.0        433397.0           NaN         1100.0    44074.0   \n",
       "4.0       39936159.0        235903.0           NaN            NaN    36170.0   \n",
       "5.0       16153057.0       1151578.0       71639.0            NaN   214054.0   \n",
       "...              ...             ...           ...            ...        ...   \n",
       "196.0       560064.0         18617.0       16476.0           71.0     4034.0   \n",
       "197.0       551596.0         16578.0        3001.0            NaN        NaN   \n",
       "NaN              NaN         20142.0       10320.0           65.0     5673.0   \n",
       "199.0       533644.0         27014.0       11508.0           68.0     1144.0   \n",
       "200.0            NaN         36741.0       10300.0           98.0     6652.0   \n",
       "\n",
       "       Avg_viewers  Avg_channels  Avg_viewer_ratio  \n",
       "Rank                                                \n",
       "1.0       127021.0           NaN             69.29  \n",
       "2.0        64378.0        1117.0             57.62  \n",
       "3.0        60815.0         583.0            104.26  \n",
       "4.0        53749.0         317.0            169.29  \n",
       "5.0        21740.0        1549.0             14.03  \n",
       "...            ...           ...               ...  \n",
       "196.0        778.0          25.0             30.08  \n",
       "197.0        767.0          23.0             33.27  \n",
       "NaN          752.0          28.0             26.85  \n",
       "199.0          NaN          37.0             19.75  \n",
       "200.0        737.0          51.0               NaN  \n",
       "\n",
       "[18600 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¥ Game: Inconsistent (str, float)\n",
      "üî¥ Month_str: Inconsistent (float, str)\n",
      "üü¢ Month: Consistent (float)\n",
      "üü¢ Year: Consistent (float)\n",
      "üü¢ YearTop1: Consistent (bool)\n",
      "üü¢ Hours_watched: Consistent (float)\n",
      "üü¢ Hours_streamed: Consistent (float)\n",
      "üü¢ Peak_viewers: Consistent (float)\n",
      "üü¢ Peak_channels: Consistent (float)\n",
      "üü¢ Streamers: Consistent (float)\n",
      "üü¢ Avg_viewers: Consistent (float)\n",
      "üü¢ Avg_channels: Consistent (float)\n",
      "üü¢ Avg_viewer_ratio: Consistent (float)\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store type consistency results\n",
    "type_consistency = {}\n",
    "\n",
    "# Iterate through DataFrame columns\n",
    "for column in datac:\n",
    "    # Get the unique data types in the column\n",
    "    unique_types = datac[column].apply(type).unique()\n",
    "    \n",
    "    # Check if there's more than one unique data type\n",
    "    if len(unique_types) == 1:\n",
    "        type_consistency[column] = f\"üü¢ {column}: Consistent ({unique_types[0].__name__})\"\n",
    "    else:\n",
    "        type_consistency[column] = f\"üî¥ {column}: Inconsistent ({', '.join(t.__name__ for t in unique_types)})\"\n",
    "\n",
    "# Print the type consistency results for each feature\n",
    "for consistency in type_consistency.values():\n",
    "    print(consistency)\n",
    "    #output_file.write(consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datac.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type inconsistency is tied to the NaN values we have in our dataset\n",
    "\n",
    "We need to manage that with the KNN method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - KNN Imputing for quantitative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Selecting only the quantitative columns\n",
    "quantitative_cols = datac.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "datac[quantitative_cols] = imputer.fit_transform(datac[quantitative_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Month               0\n",
       "Year                0\n",
       "Hours_watched       0\n",
       "Hours_streamed      0\n",
       "Peak_viewers        0\n",
       "Peak_channels       0\n",
       "Streamers           0\n",
       "Avg_viewers         0\n",
       "Avg_channels        0\n",
       "Avg_viewer_ratio    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datac[quantitative_cols].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - KNN Imputing for qualitative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Step 1: One-Hot Encode\\ndatac_encoded = pd.get_dummies(datac, columns=datac.select_dtypes(include=[\\'object\\']).columns, drop_first=False)\\n\\n# Step 2: Apply KNN Imputation\\nimputer = KNNImputer(n_neighbors=5)\\ndatac_imputed = pd.DataFrame(imputer.fit_transform(datac_encoded), columns=datac_encoded.columns)\\n\\n# Step 3: Post-process the Imputed Values\\nfor col in datac.select_dtypes(include=[\\'object\\']).columns:\\n    dummies = [col_ for col_ in datac_encoded.columns if col_.startswith(col + \"_\")]\\n    # For each row, find the column with the highest imputed value\\n    max_col = datac_imputed[dummies].idxmax(axis=1)\\n    # Strip the prefix to get original category\\n    datac[col] = max_col.str.replace(col + \"_\", \"\")\\n\\n# Step 4: Drop the one-hot encoded columns from the original dataframe as they\\'re no longer needed\\ndatac.drop(columns=datac_encoded.columns.difference(datac.columns), inplace=True)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Step 1: One-Hot Encode\n",
    "datac_encoded = pd.get_dummies(datac, columns=datac.select_dtypes(include=['object']).columns, drop_first=False)\n",
    "\n",
    "# Step 2: Apply KNN Imputation\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "datac_imputed = pd.DataFrame(imputer.fit_transform(datac_encoded), columns=datac_encoded.columns)\n",
    "\n",
    "# Step 3: Post-process the Imputed Values\n",
    "for col in datac.select_dtypes(include=['object']).columns:\n",
    "    dummies = [col_ for col_ in datac_encoded.columns if col_.startswith(col + \"_\")]\n",
    "    # For each row, find the column with the highest imputed value\n",
    "    max_col = datac_imputed[dummies].idxmax(axis=1)\n",
    "    # Strip the prefix to get original category\n",
    "    datac[col] = max_col.str.replace(col + \"_\", \"\")\n",
    "\n",
    "# Step 4: Drop the one-hot encoded columns from the original dataframe as they're no longer needed\n",
    "datac.drop(columns=datac_encoded.columns.difference(datac.columns), inplace=True)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Imputing for qualitative data was too complicated to implement without issues.\n",
    "I could try using label encoding before using the KNN Imputing however my categorical data is nominal and not ordinal.\n",
    "\n",
    "Therefore I have decided to use a different method :\n",
    "- **Mode imputation** : No. I don't want to bias my model with the most frequent value since there is no reason to replace every NaN (11% of the dataset) with this value.\n",
    "- **Random imputation** : No. I am creating false information in my dataset that can confuse my model.\n",
    "- **Drop rows** : Possible. This is a possibility I was thinking about as a last resort if I couldn't find an other solution, since it's very destructive.\n",
    "- **Constant imputation** : Yes. The method I am going with. I am going to accept the fact that I don't know certain 'Game' data and replace these NaNs with 'Unknown', thus my model will still train with 100% of the data I give it. The model will maybe predict 'Unkown' data but I prefer predicting that I can't be certain of an information than predicting a false information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 - Constant Imputation for qualitative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only the categorical columns\n",
    "categorical_columns = datac.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Replace NaN values in categorical columns with 'Unknown'\n",
    "datac[categorical_columns] = datac[categorical_columns].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game</th>\n",
       "      <th>Month_str</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>YearTop1</th>\n",
       "      <th>Hours_watched</th>\n",
       "      <th>Hours_streamed</th>\n",
       "      <th>Peak_viewers</th>\n",
       "      <th>Peak_channels</th>\n",
       "      <th>Streamers</th>\n",
       "      <th>Avg_viewers</th>\n",
       "      <th>Avg_channels</th>\n",
       "      <th>Avg_viewer_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>League of Legends</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>False</td>\n",
       "      <td>94377226.0</td>\n",
       "      <td>1362044.0</td>\n",
       "      <td>530270.0</td>\n",
       "      <td>2903.0</td>\n",
       "      <td>129172.0</td>\n",
       "      <td>127021.0</td>\n",
       "      <td>1742.8</td>\n",
       "      <td>69.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>True</td>\n",
       "      <td>47832863.0</td>\n",
       "      <td>830105.0</td>\n",
       "      <td>372654.0</td>\n",
       "      <td>2197.0</td>\n",
       "      <td>30256.6</td>\n",
       "      <td>64378.0</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>57.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>Dota 2</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>False</td>\n",
       "      <td>45185893.0</td>\n",
       "      <td>433397.0</td>\n",
       "      <td>169907.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>44074.0</td>\n",
       "      <td>60815.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>104.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>Hearthstone</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>False</td>\n",
       "      <td>39936159.0</td>\n",
       "      <td>235903.0</td>\n",
       "      <td>94691.4</td>\n",
       "      <td>619.4</td>\n",
       "      <td>36170.0</td>\n",
       "      <td>53749.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>169.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>Call of Duty: Black Ops III</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>False</td>\n",
       "      <td>16153057.0</td>\n",
       "      <td>1151578.0</td>\n",
       "      <td>71639.0</td>\n",
       "      <td>484.2</td>\n",
       "      <td>214054.0</td>\n",
       "      <td>21740.0</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>14.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196.0</th>\n",
       "      <td>PlateUp!</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>False</td>\n",
       "      <td>560064.0</td>\n",
       "      <td>18617.0</td>\n",
       "      <td>16476.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>4034.0</td>\n",
       "      <td>778.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>30.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197.0</th>\n",
       "      <td>Pok√É¬©mon GO</td>\n",
       "      <td>September</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>False</td>\n",
       "      <td>551596.0</td>\n",
       "      <td>16578.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>121.6</td>\n",
       "      <td>4070.8</td>\n",
       "      <td>767.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>33.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>Bloons TD 6</td>\n",
       "      <td>September</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>False</td>\n",
       "      <td>444984.0</td>\n",
       "      <td>20142.0</td>\n",
       "      <td>10320.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>5673.0</td>\n",
       "      <td>752.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199.0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>September</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>False</td>\n",
       "      <td>533644.0</td>\n",
       "      <td>27014.0</td>\n",
       "      <td>11508.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>1012.6</td>\n",
       "      <td>37.0</td>\n",
       "      <td>19.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200.0</th>\n",
       "      <td>Bloodborne</td>\n",
       "      <td>September</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>False</td>\n",
       "      <td>437310.0</td>\n",
       "      <td>36741.0</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>737.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>28.022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18600 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Game  Month_str  Month    Year  YearTop1  \\\n",
       "Rank                                                                          \n",
       "1.0                   League of Legends    Unknown    1.0  2016.0     False   \n",
       "2.0    Counter-Strike: Global Offensive    January    1.0  2016.0      True   \n",
       "3.0                              Dota 2    January    1.0  2016.0     False   \n",
       "4.0                         Hearthstone    January    1.0  2016.0     False   \n",
       "5.0         Call of Duty: Black Ops III    January    1.0  2016.0     False   \n",
       "...                                 ...        ...    ...     ...       ...   \n",
       "196.0                          PlateUp!    Unknown    9.0  2023.0     False   \n",
       "197.0                       Pok√É¬©mon GO  September    9.0  2023.0     False   \n",
       "NaN                         Bloons TD 6  September    9.0  2023.0     False   \n",
       "199.0                           Unknown  September    9.0  2023.0     False   \n",
       "200.0                        Bloodborne  September    9.0  2023.0     False   \n",
       "\n",
       "       Hours_watched  Hours_streamed  Peak_viewers  Peak_channels  Streamers  \\\n",
       "Rank                                                                           \n",
       "1.0       94377226.0       1362044.0      530270.0         2903.0   129172.0   \n",
       "2.0       47832863.0        830105.0      372654.0         2197.0    30256.6   \n",
       "3.0       45185893.0        433397.0      169907.0         1100.0    44074.0   \n",
       "4.0       39936159.0        235903.0       94691.4          619.4    36170.0   \n",
       "5.0       16153057.0       1151578.0       71639.0          484.2   214054.0   \n",
       "...              ...             ...           ...            ...        ...   \n",
       "196.0       560064.0         18617.0       16476.0           71.0     4034.0   \n",
       "197.0       551596.0         16578.0        3001.0          121.6     4070.8   \n",
       "NaN         444984.0         20142.0       10320.0           65.0     5673.0   \n",
       "199.0       533644.0         27014.0       11508.0           68.0     1144.0   \n",
       "200.0       437310.0         36741.0       10300.0           98.0     6652.0   \n",
       "\n",
       "       Avg_viewers  Avg_channels  Avg_viewer_ratio  \n",
       "Rank                                                \n",
       "1.0       127021.0        1742.8            69.290  \n",
       "2.0        64378.0        1117.0            57.620  \n",
       "3.0        60815.0         583.0           104.260  \n",
       "4.0        53749.0         317.0           169.290  \n",
       "5.0        21740.0        1549.0            14.030  \n",
       "...            ...           ...               ...  \n",
       "196.0        778.0          25.0            30.080  \n",
       "197.0        767.0          23.0            33.270  \n",
       "NaN          752.0          28.0            26.850  \n",
       "199.0       1012.6          37.0            19.750  \n",
       "200.0        737.0          51.0            28.022  \n",
       "\n",
       "[18600 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datac.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We don't have any missing values anymore, we can now start modelling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datac_encode = datac.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datac_encode.drop('Month_str', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "datac_encode = pd.get_dummies(datac_encode, columns=['Game'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 18600 entries, 1.0 to 200.0\n",
      "Columns: 2055 entries, Month to Game_theHunter: Call of the Wild\n",
      "dtypes: bool(1), float64(10), uint8(2044)\n",
      "memory usage: 37.8 MB\n"
     ]
    }
   ],
   "source": [
    "datac_encode.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our binary outcome is going to be 'YearTop1' which is assessing if the selected 'Game' had the highest average concurrent viewership of the said year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Dataset Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (14880, 2055)\n",
      "Test data shape: (3720, 2055)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets with 80% and 20% of the data respectively\n",
    "train_datac, test_datac = train_test_split(datac_encode, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training data shape:\", train_datac.shape)\n",
    "print(\"Test data shape:\", test_datac.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Metrics:\n",
      "Accuracy: 1.0\n",
      "ROC AUC: 1.0\n",
      "F1 Score: 1.0\n",
      "Cohen's Kappa: 1.0\n",
      "\n",
      "\n",
      "Test Data Metrics:\n",
      "Accuracy: 0.8798387096774194\n",
      "ROC AUC: 0.4989329268292683\n",
      "F1 Score: 0.0\n",
      "Cohen's Kappa: -0.003718279933360602\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, cohen_kappa_score\n",
    "\n",
    "# Assuming the target variable is named 'target'. Please replace 'target' with the correct column name if different.\n",
    "y_train = train_datac['YearTop1']\n",
    "X_train = train_datac.drop('YearTop1', axis=1)\n",
    "y_test = test_datac['YearTop1']\n",
    "X_test = test_datac.drop('YearTop1', axis=1)\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on training and test sets\n",
    "train_preds = clf.predict(X_train)\n",
    "test_preds = clf.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics for training data\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "train_roc_auc = roc_auc_score(y_train, train_preds)\n",
    "train_f1 = f1_score(y_train, train_preds)\n",
    "train_kappa = cohen_kappa_score(y_train, train_preds)\n",
    "\n",
    "# Calculate performance metrics for test data\n",
    "test_accuracy = accuracy_score(y_test, test_preds)\n",
    "test_roc_auc = roc_auc_score(y_test, test_preds)\n",
    "test_f1 = f1_score(y_test, test_preds)\n",
    "test_kappa = cohen_kappa_score(y_test, test_preds)\n",
    "\n",
    "print(f\"Training Data Metrics:\\nAccuracy: {train_accuracy}\\nROC AUC: {train_roc_auc}\\nF1 Score: {train_f1}\\nCohen's Kappa: {train_kappa}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Test Data Metrics:\\nAccuracy: {test_accuracy}\\nROC AUC: {test_roc_auc}\\nF1 Score: {test_f1}\\nCohen's Kappa: {test_kappa}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a function that automates the training of different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Metrics:\n",
      "Training Data: Accuracy=1.0, ROC AUC=1.0\n",
      "Test Data: Accuracy=0.8798387096774194, ROC AUC=0.4989329268292683\n",
      "\n",
      "\n",
      "LogisticRegression Metrics:\n",
      "Training Data: Accuracy=0.8846102150537635, ROC AUC=0.5\n",
      "Test Data: Accuracy=0.8817204301075269, ROC AUC=0.5\n",
      "\n",
      "\n",
      "GradientBoostingClassifier Metrics:\n",
      "Training Data: Accuracy=0.8854166666666666, ROC AUC=0.5034944670937682\n",
      "Test Data: Accuracy=0.8811827956989248, ROC AUC=0.4996951219512195\n",
      "\n",
      "\n",
      "The best classifier is LogisticRegression based on ROC AUC score.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def evaluate_classifier(classifier, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Function : Train the classifier and compute metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fit the classifier\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on training and test sets\n",
    "    train_preds = classifier.predict(X_train)\n",
    "    test_preds = classifier.predict(X_test)\n",
    "\n",
    "    # Calculate performance metrics for training data\n",
    "    train_accuracy = accuracy_score(y_train, train_preds)\n",
    "    train_roc_auc = roc_auc_score(y_train, train_preds)\n",
    "    train_f1 = f1_score(y_train, train_preds)\n",
    "    train_kappa = cohen_kappa_score(y_train, train_preds)\n",
    "\n",
    "    # Calculate performance metrics for test data\n",
    "    test_accuracy = accuracy_score(y_test, test_preds)\n",
    "    test_roc_auc = roc_auc_score(y_test, test_preds)\n",
    "    test_f1 = f1_score(y_test, test_preds)\n",
    "    test_kappa = cohen_kappa_score(y_test, test_preds)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"{classifier.__class__.__name__} Metrics:\")\n",
    "    print(f\"Training Data: Accuracy={train_accuracy}, ROC AUC={train_roc_auc}, F1 Score={train_f1}, Cohen's Kappa={train_kappa}\")\n",
    "    print(f\"Test Data: Accuracy={test_accuracy}, ROC AUC={test_roc_auc}, F1 Score={test_f1}, Cohen's Kappa={test_kappa}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return test_accuracy, test_roc_auc, test_f1, test_kappa\n",
    "\n",
    "\n",
    "# Initialize classifiers\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "lr = LogisticRegression(random_state=42, max_iter=10000)\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Evaluate classifiers\n",
    "results = {}\n",
    "results[\"RandomForest\"] = evaluate_classifier(rf, X_train, y_train, X_test, y_test)\n",
    "results[\"LogisticRegression\"] = evaluate_classifier(lr, X_train, y_train, X_test, y_test)\n",
    "results[\"GradientBoosting\"] = evaluate_classifier(gb, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Determine the best classifier based on test ROC AUC\n",
    "best_classifier = max(results, key=lambda k: results[k][1])\n",
    "print(f\"The best classifier is {best_classifier} based on ROC AUC score.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-award",
   "metadata": {},
   "source": [
    "**III- Multiclass Classification** (Optional with good bonus point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-crack",
   "metadata": {},
   "source": [
    "This time, select a categorical variable having more than 2 categories. I you have none, then categorize one of your quantitative data (e.g in using `pd.cut()` and the corresponding quantiles) into at least three classes.\n",
    "\n",
    "Copy the codes of PART I and adjust to the new outcome. Use only Accuracy and F1 Score for performance (or sklearn `classification_report`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multiclass classification of a categorical variable, we are going to need to stratify our data before splitting so we keep the same data distribution between our values in our training dataset and testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Dataset Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (13644, 12)\n",
      "Test data shape: (3411, 12)\n"
     ]
    }
   ],
   "source": [
    "# Filter out categories in 'Game' with less than 3 instances (needed for stratification!)\n",
    "datac_filtered = datac[datac.groupby('Game')['Game'].transform('size') > 2]\n",
    "\n",
    "# Perform the stratified split on the filtered data\n",
    "y_filtered = datac_filtered['Game']\n",
    "X_filtered = datac_filtered.drop('Game', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_filtered, y_filtered, test_size=0.2, random_state=42, stratify=y_filtered)\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Test data shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Training data shape: (13644, 23)\n",
      "Encoded Test data shape: (3411, 23)\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Perform dummy encoding for the training data\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=categorical_cols, drop_first=True)\n",
    "y_train_encoded = pd.get_dummies(y_train, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Perform dummy encoding for the test data\n",
    "# Note: Use the columns from the training data to ensure consistency\n",
    "X_test_encoded = pd.get_dummies(X_test, columns=categorical_cols, drop_first=True).reindex(columns=X_train_encoded.columns, fill_value=0)\n",
    "y_test_encoded = pd.get_dummies(y_test, columns=categorical_cols, drop_first=True).reindex(columns=y_train_encoded.columns, fill_value=0)\n",
    "\n",
    "print(\"Encoded Training data shape:\", X_train_encoded.shape)\n",
    "print(\"Encoded Test data shape:\", X_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-4f21e42dbbea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Evaluate classifiers using the previously defined function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mresults_filtered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mresults_filtered\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"RandomForest\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_encoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mresults_filtered\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"LogisticRegression\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_encoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mresults_filtered\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"GradientBoosting\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_encoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-ffe3f6b1b4b8>\u001b[0m in \u001b[0;36mevaluate_classifier\u001b[1;34m(classifier, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Calculate performance metrics for test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mtest_roc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# Print results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programmes\\Anaconda\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m                     )\n\u001b[0;32m    210\u001b[0m                 ):\n\u001b[1;32m--> 211\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m                 \u001b[1;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programmes\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    633\u001b[0m         )\n\u001b[0;32m    634\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# multilabel-indicator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         return _average_binary_score(\n\u001b[0m\u001b[0;32m    636\u001b[0m             \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_fpr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_fpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programmes\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0my_true_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnot_average_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0my_score_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnot_average_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscore_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;31m# Average the results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programmes\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;34m\"\"\"Binary roc auc score.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    383\u001b[0m             \u001b[1;34m\"Only one class present in y_true. ROC AUC score \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;34m\"is not defined in that case.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "# Evaluate classifiers using the previously defined function\n",
    "results_filtered = {}\n",
    "\"\"\"\n",
    "results_filtered[\"RandomForest\"] = evaluate_classifier(rf, X_train_encoded, y_train_encoded, X_test_encoded, y_test_encoded)\n",
    "results_filtered[\"LogisticRegression\"] = evaluate_classifier(lr, X_train_encoded, y_train_encoded, X_test_encoded, y_test_encoded)\n",
    "results_filtered[\"GradientBoosting\"] = evaluate_classifier(gb, X_train_encoded, y_train_encoded, X_test_encoded, y_test_encoded)\n",
    "\"\"\"\n",
    "\n",
    "# Determine the best classifier based on test Accuracy\n",
    "best_classifier_filtered = max(results_filtered, key=lambda k: results_filtered[k][0])\n",
    "print(f\"The best classifier is {best_classifier_filtered} based on Accuracy score.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
